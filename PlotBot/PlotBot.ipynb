{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PlotBot\n",
    "\n",
    "Build a Twitter bot that sends out visualized sentiment analysis of a Twitter account's recent tweets.\n",
    "\n",
    "Visit [https://twitter.com/PlotBot5](https://twitter.com/PlotBot5) for an example of what your script should do.\n",
    "\n",
    "The bot receives tweets via mentions and in turn performs sentiment analysis on the most recent twitter account specified in the mention\n",
    "\n",
    "For example, when a user tweets, __\"@PlotBot Analyze: @CNN,\"__ it will trigger a sentiment analysis on the CNN twitter feed.\n",
    "\n",
    "A plot from the sentiment analysis is then tweeted to the PlotBot5 twitter feed. See below for examples of scatter plots you will generate:\n",
    "\n",
    "![@juanitasoranno.png](images/@juanitasoranno.png)\n",
    "\n",
    "Hints, requirements, and considerations:\n",
    "\n",
    "* Your bot should scan your account every __five minutes__ for mentions.\n",
    "* Your bot should pull 500 most recent tweets to analyze for each incoming request.\n",
    "* Your script should prevent abuse by analyzing __only__ Twitter accounts that have not previously been analyzed.\n",
    "* Your plot should include meaningful legend and labels.\n",
    "* It should also mention the Twitter account name of the requesting user.\n",
    "* When submitting your assignment, be sure to have at least __three__ analyses tweeted out from your account (enlist the help of classmates, friends, or family, if necessary!).\n",
    "* Notable libraries used to complete this application include: Matplotlib, Pandas, Tweepy, TextBlob, and Seaborn.\n",
    "* You may find it helpful to organize your code in function(s), then call them.\n",
    "* If you're not yet familiar with creating functions in Python, here is a tutorial you may wish to consult: [https://www.tutorialspoint.com/python/python_functions.htm](https://www.tutorialspoint.com/python/python_functions.htm)\n",
    "Your final Jupyter notebook must:\n",
    "\n",
    "* Pull last 100 tweets from each outlet.\n",
    "* Perform a sentiment analysis with the compound, positive, neutral, and negative scoring for each tweet.\n",
    "* Pull into a DataFrame the tweet's source acount, its text, its date, and its compound, positive, neutral, and negative sentiment scores.\n",
    "* Export the data in the DataFrame into a CSV file.\n",
    "* Save PNG images for each plot.\n",
    "\n",
    "As final considerations:\n",
    "\n",
    "* Use the Matplotlib and Seaborn libraries.\n",
    "* Include a written description of three observable trends based on the data.\n",
    "* Include proper labeling of your plots, including plot titles (with date of analysis) and axes labels.\n",
    "* Include an exported markdown version of your Notebook called  `README.md` in your GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from config import *\n",
    "import os\n",
    "# Import and Initialize Sentiment Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import ast\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter API Keys\n",
    "consumer_key = consumer_key\n",
    "consumer_secret = consumer_secret\n",
    "access_token = access_token\n",
    "access_token_secret = access_token_secret\n",
    "\n",
    "# Twitter credentials\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rwCSV(path,rw='r',df=None,columns=None):\n",
    "    '''\n",
    "    Reads CSV from path to pandas dataframe (rw='r')\n",
    "    Writes/appends to CSV path from pandas dataframe (rw='w')\n",
    "    Columns: array-like\n",
    "    '''\n",
    "    if rw=='r':\n",
    "        if os.path.isfile(path): \n",
    "            print('rwCSV: returning DF from CSV')\n",
    "            return pd.read_csv(path)\n",
    "        else: \n",
    "            print(f'rwCSV: returning new DF with columns: {columns}')\n",
    "            return pd.DataFrame(columns=columns)\n",
    "    elif rw=='w':\n",
    "        df = pd.DataFrame(df)\n",
    "        # if file does not exist write with header \n",
    "        if not os.path.isfile(path):\n",
    "            df.to_csv(path,index=False, columns=columns)\n",
    "            print(f\"rwCSV: saved {df.shape[0]} row(s) as new file to '{path}'\")\n",
    "        else: # else it exists so append without writing the header\n",
    "            df.to_csv(path,mode = 'a',header=False,index=False, columns=columns)\n",
    "            print(f\"rwCSV: appended {df.shape[0]} row(s) to '{path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMentions():\n",
    "    '''\n",
    "    gets mentions from twitter and saves to CSV file\n",
    "    '''\n",
    "    #set up resulting columns\n",
    "    columns = ['mention_tweet_id','text','mentioned_users','mention_date', \\\n",
    "               'mention_user_id','mention_user_name','full_response']\n",
    "\n",
    "    #set up my twitter account number\n",
    "    my_id = api.me()['id']\n",
    "\n",
    "    #get mentions\n",
    "    try:\n",
    "        mention_response = api.mentions_timeline()\n",
    "        #print('got some kind of response')\n",
    "    except tweepy.TweepError as e:\n",
    "        print(f\"getMentions: Something's not right. Error: {e}\")\n",
    "        mention_response = False\n",
    "\n",
    "    #if there are mentions go on\n",
    "    if mention_response:\n",
    "        print(f'getMentions: Got response with {len(mention_response)} tweet(s)')\n",
    "\n",
    "        # try reading mentions CSV\n",
    "        path = 'results/mentions.csv'\n",
    "        mentions_df = rwCSV(path,columns=columns)\n",
    "        new_mentions_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "        #add mentions to a DF\n",
    "        for response in mention_response:\n",
    "            #set up mentioned list\n",
    "            mentioned_list = []\n",
    "\n",
    "            #create list of mentioned users\n",
    "            for mention in response['entities']['user_mentions']:\n",
    "                if mention['id'] != my_id:\n",
    "                    print(f\"getMentions: adding mention id: {mention['id']}\")\n",
    "                    mentioned_list.append(mention['id'])\n",
    "\n",
    "            #check if the tweet has already been added to DF\n",
    "            #and that there are in fact mentioned users in the tweet\n",
    "            if response['id'] not in mentions_df['mention_tweet_id'].tolist() and \\\n",
    "                len(mentioned_list) > 0:\n",
    "                mentions_dict = {'mention_tweet_id':response['id'],\n",
    "                                 'text':response['text'],\n",
    "                                 'mentioned_users':mentioned_list,\n",
    "                                 'mention_date':response['created_at'],\n",
    "                                 'mention_user_id':response['user']['id'],\n",
    "                                 'mention_user_name':response['user']['name'],\n",
    "                                 'full_response':response \\\n",
    "                                }\n",
    "                #grab all the mentions (append to CSV)\n",
    "                mentions_df = mentions_df.append(mentions_dict,ignore_index=True)\n",
    "                \n",
    "                #grab only new mentions (append to empty DF)\n",
    "                new_mentions_df = new_mentions_df.append(mentions_dict,ignore_index=True)\n",
    "                #convert dates\n",
    "                mentions_df['mention_date'] = pd.to_datetime(mentions_df['mention_date'])\n",
    "                new_mentions_df['mention_date'] = pd.to_datetime(mentions_df['mention_date'])\n",
    "            else:\n",
    "                print(f\"getMentions: Tweet id: {response['id']} is in CSV already or doesn't have a valid mentioned user\")\n",
    "        #save to CSV\n",
    "        if new_mentions_df.shape[0] > 0:\n",
    "            print(f'getMentions: saving new mentions to CSV')\n",
    "            rwCSV(path,'w',new_mentions_df,columns)\n",
    "        else:\n",
    "            print('getMentions: No new mentions')\n",
    "\n",
    "    #if getMentions() responded with False\n",
    "    else: \n",
    "        print('getMentions: No new mentions')\n",
    "    return mentions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentiment(id,pages=1):\n",
    "    '''\n",
    "    Returns 'pages'*100 compound sentiment analysis for twitter user 'id'\n",
    "    '''\n",
    "    mentioned_user = id\n",
    "    \n",
    "    if pages > 5: pages = 5\n",
    "    else: pages = pages\n",
    "        \n",
    "    count = 100\n",
    "\n",
    "    sentiment_df = pd.DataFrame()\n",
    "    \n",
    "    #setup list for tweets\n",
    "    tweets_of_mentioned_user = []\n",
    "\n",
    "    #get and analyse tweets\n",
    "    for page in range(1,pages+1):\n",
    "\n",
    "        #get 100 tweets at once\n",
    "        print(f'getSentiment: trying to obtain tweets for user id {mentioned_user}, page {page}')\n",
    "        try:\n",
    "            public_tweets = api.user_timeline(id=mentioned_user,count=count,page=page)\n",
    "        except:\n",
    "            public_tweets = False\n",
    "\n",
    "        #loop through obtained tweets\n",
    "        if public_tweets:\n",
    "            for tweet in public_tweets:\n",
    "                result = analyzer.polarity_scores(tweet[\"text\"])\n",
    "\n",
    "                sentiment_dict = {\n",
    "                    'user_id':mentioned_user,\n",
    "                    'date':tweet['created_at'],\n",
    "                    'tweet':tweet[\"text\"],\n",
    "                    'compound':result['compound'],\n",
    "                    'positive':result['pos'],\n",
    "                    'neutral':result['neu'],\n",
    "                    'negative':result['neg']\n",
    "                }\n",
    "\n",
    "                #grab all the mentions\n",
    "                sentiment_df = sentiment_df.append(sentiment_dict,ignore_index=True)\n",
    "\n",
    "    return sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeGraph(df,mentioned_user):\n",
    "    path = 'results/image_' + str(mentioned_user) + '.png'\n",
    "    mentioned_user_name = api.get_user(mentioned_user)['screen_name']\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    f, ax = plt.subplots(figsize=(20,10))\n",
    "    df.plot(marker=\"o\",markersize=10,linewidth=0.5, alpha=0.8)\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.xlim([len(df.index),0])\n",
    "    plt.ylabel(\"Tweet polarity \\n<negative.........positive>\")\n",
    "    plt.xlabel(\"Tweets Ago\")\n",
    "    now = datetime.now()\n",
    "    now = now.strftime(\"%m/%d/%Y\")\n",
    "    plt.title(f\"Sentiment analysis of @{mentioned_user_name} tweets as of {now}\")\n",
    "    plt.savefig(path, format='png')\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "    api.update_with_media(path)\n",
    "    return mentioned_user_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker():\n",
    "    #get new mentions as DF\n",
    "    mentions_df = getMentions()\n",
    "\n",
    "    #setup resulting CSV\n",
    "    path_to_analyzed = 'results/analyzed.csv'\n",
    "    path_to_sentiment = 'results/sentiment.csv'\n",
    "    columns_analyzed = ['user_id','user_name']\n",
    "    columns_sentiment = ['user_id','date','tweet','compound','positive','negative','neutral']\n",
    "    print('worker: trying to read analyzed CSV')\n",
    "    analyzed_df = rwCSV(path,columns=columns_analyzed)\n",
    "\n",
    "    #got through not analyzed rows\n",
    "    for index, row in mentions_df.iterrows():\n",
    "        #get the list of mentioned users\n",
    "        #Note. for some reason `row` returns a string type variable and not list\n",
    "        #therefore using ast.literal_eval function to convert it to list\n",
    "        \n",
    "        if row['mentioned_users']:\n",
    "            mentioned_users = ast.literal_eval(str(row['mentioned_users']))\n",
    "            #loop through the list to analyse tweets and post graphs\n",
    "            for mentioned_user in mentioned_users:\n",
    "                if mentioned_user not in analyzed_df['user_id'].tolist():\n",
    "                    print(f'worker: performing sentiment analysis for user_id {mentioned_user}')\n",
    "                    sentiment = getSentiment(mentioned_user,pages=5)\n",
    "                    rwCSV(path_to_sentiment,'w',df=sentiment,columns = columns_sentiment)\n",
    "\n",
    "                    print(f'worker: performed sentiment analysis for user_id {mentioned_user}')\n",
    "                    mentioned_user_name = makeGraph(sentiment['compound'],mentioned_user)\n",
    "                    print(f'worker: generated and tweeted graph for @{mentioned_user_name}')\n",
    "\n",
    "                    #change flag to analyzed and save CSV\n",
    "                    analyzed_df = analyzed_df.append({'user_name':mentioned_user_name,\n",
    "                                                      'user_id':mentioned_user\n",
    "                                                      },ignore_index=True)\n",
    "                    rwCSV(path_to_analyzed,'w',analyzed_df,columns)\n",
    "                else:\n",
    "                    print(f'worker: user id: {mentioned_user} has already been analyzed')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing worker:\n",
      "getMentions: Got response with 4 tweet(s)\n",
      "rwCSV: returning DF from CSV\n",
      "getMentions: adding mention id: 80067314\n",
      "getMentions: Tweet id: 985700911614918658 is in CSV already or doesn't have a valid mentioned user\n",
      "getMentions: adding mention id: 17842366\n",
      "getMentions: Tweet id: 983829906302873601 is in CSV already or doesn't have a valid mentioned user\n",
      "getMentions: adding mention id: 979490736013021184\n",
      "getMentions: Tweet id: 983757509960839168 is in CSV already or doesn't have a valid mentioned user\n",
      "getMentions: Tweet id: 983698615347613696 is in CSV already or doesn't have a valid mentioned user\n",
      "getMentions: No new mentions\n",
      "worker: trying to read analyzed CSV\n",
      "rwCSV: returning DF from CSV\n",
      "worker: user id: 17842366 has already been analyzed\n",
      "worker: user id: 979490736013021184 has already been analyzed\n",
      "worker: user id: 80067314 has already been analyzed\n"
     ]
    }
   ],
   "source": [
    "# run the program\n",
    "if __name__ == '__main__':\n",
    "    while True:\n",
    "        print('Initializing worker:')\n",
    "        worker()\n",
    "        sleep(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trends\n",
    "1. Bot of a fellow student appeares to be tweeting neutral texts\n",
    "2. @Discovery tends to be more positive\n",
    "3. @ITSJPODirector is vastly positive on twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
